# --- Advanced Feature: Memory Scan ---
import psutil

def scan_memory_with_yara(show_signature=False):
    """
    Scan running processes' memory with all compiled YARA rules.
    Requires yara-python with process scanning support and psutil.
    """
    rules = compile_yara_rules()
    print_result("[*] Scanning all running processes with YARA...", "info")
    for proc in psutil.process_iter(['pid', 'name']):
        try:
            pid = proc.info['pid']
            name = proc.info['name']
            print_result(f"[Memory Scan] PID {pid} ({name})", "info")
            for rule_name, rule in rules.items():
                try:
                    matches = rule.match(pid=pid)
                except Exception as e:
                    print_result(f"Error scanning PID {pid} with {rule_name}: {e}", "error")
                    continue
                if matches:
                    print_result(f"[!] Threat detected in PID {pid} by {rule_name}:", "danger")
                    for match in matches:
                        print_result(f"    Rule: {match.rule}", "danger")
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue



# --- Core dependencies ---
import os
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- Third-party libraries ---
import yara
import pefile

# --- Internal modules ---
from .utils import print_result
from .config import load_config


# Global cache for compiled YARA rules
_YARA_RULES_CACHE = None


def get_rules_dir():
    """Get the directory containing YARA rules from config."""
    config = load_config()
    return config.get("rules_dir")


def compile_yara_rules():
    """Compile all YARA rules in the rules directory and cache them."""
    global _YARA_RULES_CACHE
    if _YARA_RULES_CACHE is not None:
        return _YARA_RULES_CACHE
    rules_dir = get_rules_dir()
    rule_files = [f for f in os.listdir(rules_dir) if f.endswith(".yar")]
    rules = {}
    for rule_file in rule_files:
        path = os.path.join(rules_dir, rule_file)
        try:
            rules[rule_file] = yara.compile(filepath=path)
        except yara.SyntaxError as e:
            print_result(f"YARA syntax error in {rule_file}: {e}", "error")
    _YARA_RULES_CACHE = rules
    return rules


def hash_file(file_path):
    """Return SHA256 hash of a file."""
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()


def check_digital_signature(file_path):
    """Check for digital signature (PE/EXE/ELF/Mach-O). Returns True if signed, False otherwise."""
    try:
        pe = pefile.PE(file_path)
        return hasattr(pe, 'DIRECTORY_ENTRY_SECURITY')
    except Exception:
        return False


def scan_with_yara(file_path, show_signature=False):
    """Scan a single file with all compiled YARA rules."""
    if not os.path.exists(file_path):
        print_result("File does not exist!", "error")
        return

    print_result(f"[*] Scanning file: {file_path}", "info")
    rules = compile_yara_rules()
    matched = False
    for rule_name, rule in rules.items():
        try:
            matches = rule.match(file_path)
        except Exception as e:
            print_result(f"Error scanning with {rule_name}: {e}", "error")
            continue
        if matches:
            matched = True
            print_result(f"[!] Threat detected by {rule_name}:", "danger")
            for match in matches:
                print_result(f"    Rule: {match.rule}", "danger")

    if not matched:
        print_result("No YARA threats detected.", "success")

    file_hash = hash_file(file_path)
    print_result(f"SHA256 Hash: {file_hash}", "info")


def scan_directory_with_yara(directory, show_signature=False, parallelism=None):
    """Scan all files in a directory with YARA rules in parallel."""
    config = load_config()
    if parallelism is None:
        parallelism = config.get("scan_parallelism", 4)
    file_paths = []
    for root, _, files in os.walk(directory):
        for f in files:
            file_paths.append(os.path.join(root, f))
    with ThreadPoolExecutor(max_workers=parallelism) as executor:
        futures = {executor.submit(scan_with_yara, fp, show_signature): fp for fp in file_paths}
        for future in as_completed(futures):
            pass  # Results are printed by scan_with_yara
